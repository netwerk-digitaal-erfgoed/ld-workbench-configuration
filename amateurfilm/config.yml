# Metadata for your pipeline:
---
name: Amateurfilm
description: Zet de Amateurfilm datadump om naar EDM RDF voor publicatie op Europeana

# This is optional, by default it will be stored in the data directory of the pipeline using filename 'statements.nt'
destination: file://../../data/amateurfilm.nt

# The individual stages for your pipeline
stages:
  - name: "Stage 1 - Schema2EDM"
    iterator:
      query: file://iterator-stage-1.rq
      # local file takes a very long time (https://github.com/netwerk-digitaal-erfgoed/ld-workbench/issues/117)
      #endpoint: file://../../data/lod_exporter_amateurfilm_sdo_20240917_dedup.nt
      # can't use the source triple store due to issue (https://github.com/netwerk-digitaal-erfgoed/dc4eu-projects/issues/1)
      #endpoint: https://cat.apis.beeldengeluid.nl/sparql
      # advice: load the datadump into Qlever, use the IP address of the machine (127.0.0.0 or 0.0.0.0 won't work because of Docker use)
      endpoint: http://172.20.0.2:8890/
    generator:
      - query: file://generator-stage-1.rq
  # - name: "Stage 2 - GTAA SKOS"
  #   iterator:
  #     query: file://iterator-stage-2.rq
  #     endpoint: https://qlever.coret.org/ldworkbench
  #     batchSize: 50000
  #   generator:
  #     - query: file://generator-stage-2.rq
  #       endpoint: https://gtaa.apis.beeldengeluid.nl/sparql
  #       batchSize: 50000
